{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9250716,"sourceType":"datasetVersion","datasetId":5596524}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/collinslemeke/tesla-stock-prediction?scriptVersionId=195742637\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-07T23:00:52.013346Z","iopub.execute_input":"2024-09-07T23:00:52.013806Z","iopub.status.idle":"2024-09-07T23:00:52.023293Z","shell.execute_reply.started":"2024-09-07T23:00:52.013764Z","shell.execute_reply":"2024-09-07T23:00:52.021772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import all Necessary Libraries\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam\nfrom sklearn.metrics import mean_absolute_error, r2_score","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:00:52.025564Z","iopub.execute_input":"2024-09-07T23:00:52.025999Z","iopub.status.idle":"2024-09-07T23:00:52.041381Z","shell.execute_reply.started":"2024-09-07T23:00:52.025952Z","shell.execute_reply":"2024-09-07T23:00:52.039881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read the data for your use\n\ndata = pd.read_csv('/kaggle/input/tesla-stock-price-data/TSLA-2.csv')\nprint(data.columns) \ndata","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:00:52.074293Z","iopub.execute_input":"2024-09-07T23:00:52.074732Z","iopub.status.idle":"2024-09-07T23:00:52.103924Z","shell.execute_reply.started":"2024-09-07T23:00:52.074692Z","shell.execute_reply":"2024-09-07T23:00:52.102632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Date'] = pd.to_datetime(data['Date'])\n\n\ndata = data.sort_values('Date')\n\n\ndata['Year'] = data['Date'].dt.year\ndata['Month'] = data['Date'].dt.month\ndata['Day'] = data['Date'].dt.day\ndata['DayOfWeek'] = data['Date'].dt.dayofweek\ndata['Quarter'] = data['Date'].dt.quarter\n\n\ndata.set_index('Date', inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:00:52.264509Z","iopub.execute_input":"2024-09-07T23:00:52.265813Z","iopub.status.idle":"2024-09-07T23:00:52.283581Z","shell.execute_reply.started":"2024-09-07T23:00:52.26576Z","shell.execute_reply":"2024-09-07T23:00:52.281647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features to be scaled, columns and extracted features\ntsla = data[['Open', 'High', 'Low', 'Close', 'Volume', 'Year', 'Month', 'Day', 'DayOfWeek', 'Quarter']]\ntsla","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:00:52.286656Z","iopub.execute_input":"2024-09-07T23:00:52.287781Z","iopub.status.idle":"2024-09-07T23:00:52.310893Z","shell.execute_reply.started":"2024-09-07T23:00:52.287735Z","shell.execute_reply":"2024-09-07T23:00:52.309518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# perform MinMaxScaler wiht feature_range (0, 1)\n\nscaler = MinMaxScaler(feature_range = (0, 1))\nprint(scaler)\n\ncols_to_scale = ['Open', 'High', 'Low', 'Close', 'Volume', 'Year', 'Month', 'Day', 'DayOfWeek', 'Quarter']\n\ntsla_scaled = tsla.copy()\ntsla_scaled[cols_to_scale] = scaler.fit_transform(tsla[cols_to_scale])\ntsla_scaled","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:00:52.312319Z","iopub.execute_input":"2024-09-07T23:00:52.312715Z","iopub.status.idle":"2024-09-07T23:00:52.355005Z","shell.execute_reply.started":"2024-09-07T23:00:52.312669Z","shell.execute_reply":"2024-09-07T23:00:52.353684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LSTM (Long Short-Term Memory) \n\nit's a type of Recurrent Neural Network (RNN) that is particularly good at handling sequential data, such as time series, where past information plays a key role in predicting future outcomes. In our case of stock price prediction, LSTM is useful because stock prices are often influenced by trends and patterns over time.\n","metadata":{}},{"cell_type":"markdown","source":"### Reshaping the Data for LSTM:\n\nLSTM expects a 3D input in the format (samples, timesteps, features). This means youâ€™ll need to restructure your data into sequences, where each sample will have a certain number of past data points (like 10 or 30 days) as input.","metadata":{}},{"cell_type":"code","source":"sequence_length = 10\n\nX = []\ny = []\n\nfor i in range(sequence_length, len(tsla_scaled)):\n    X.append(tsla_scaled.iloc[i-sequence_length:i][cols_to_scale + ['Year', 'Month', 'Day', 'DayOfWeek', 'Quarter']].values)\n    y.append(tsla_scaled.iloc[i]['Close'])\n    \nX, y = np.array(X), np.array(y)\n\nX = np.reshape(X, (X.shape[0], X.shape[1], X.shape[2]))\n\nprint(\"Sahpe of X:\", X.shape)\nprint(\"Shape of y:\", y.shape)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:00:52.356579Z","iopub.execute_input":"2024-09-07T23:00:52.356969Z","iopub.status.idle":"2024-09-07T23:00:55.785011Z","shell.execute_reply.started":"2024-09-07T23:00:52.356931Z","shell.execute_reply":"2024-09-07T23:00:55.783814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building the LSTM Model:\nNow that the data is preprocessed and reshaped, you can define and train an LSTM model.\n\n","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n\nmodel = Sequential()\n\nmodel.add(LSTM(units = 64, return_sequences = True, input_shape = (sequence_length, X_train.shape[2])))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(32))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1))\n\n\noptimizer = keras.optimizers.Adam(learning_rate = 0.001)\nmodel.compile(optimizer = 'adam', loss = 'mse')\n\nearly_stopping = EarlyStopping(\n    monitor = 'val_loss',\n    patience = 5,\n    restore_best_weights = True)\n\nhistory = model.fit(\n    X_train, y_train,\n    epochs = 100,\n    batch_size = 64,\n    validation_data = (X_test, y_test),\n    callbacks = [early_stopping]\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:00:55.787599Z","iopub.execute_input":"2024-09-07T23:00:55.78835Z","iopub.status.idle":"2024-09-07T23:01:31.751749Z","shell.execute_reply.started":"2024-09-07T23:00:55.788305Z","shell.execute_reply":"2024-09-07T23:01:31.750487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Visualise the Training Epochs","metadata":{}},{"cell_type":"code","source":"from matplotlib.ticker import MaxNLocator\n\ndef plot_enhanced_loss(history, save_path=None):\n    # Set the style\n    plt.style.use('seaborn-whitegrid')\n    sns.set_palette(\"deep\")\n\n    # Create the plot\n    fig, ax = plt.subplots(figsize=(12, 8))\n\n    # Plot the losses\n    epochs = range(1, len(history.history['loss']) + 1)\n    ax.plot(epochs, history.history['loss'], 'b-', linewidth=2, label='Training Loss')\n    ax.plot(epochs, history.history['val_loss'], 'r-', linewidth=2, label='Validation Loss')\n\n    # Add moving averages\n    window_size = 5\n    train_ma = np.convolve(history.history['loss'], np.ones(window_size)/window_size, mode='valid')\n    val_ma = np.convolve(history.history['val_loss'], np.ones(window_size)/window_size, mode='valid')\n    ax.plot(epochs[window_size-1:], train_ma, 'b--', linewidth=1, alpha=0.7, label='Training MA')\n    ax.plot(epochs[window_size-1:], val_ma, 'r--', linewidth=1, alpha=0.7, label='Validation MA')\n\n    # Customize the plot\n    ax.set_title('Model Loss Over Epochs', fontsize=20, fontweight='bold')\n    ax.set_xlabel('Epochs', fontsize=14)\n    ax.set_ylabel('Loss', fontsize=14)\n    ax.legend(fontsize=12)\n\n    # Set x-axis to show integer values\n    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n\n    # Add annotations for minimum losses\n    min_train_loss = min(history.history['loss'])\n    min_val_loss = min(history.history['val_loss'])\n    min_train_epoch = history.history['loss'].index(min_train_loss) + 1\n    min_val_epoch = history.history['val_loss'].index(min_val_loss) + 1\n\n    ax.annotate(f'Min: {min_train_loss:.4f}', xy=(min_train_epoch, min_train_loss),\n                xytext=(10, 10), textcoords='offset points', ha='left', va='bottom',\n                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n\n    ax.annotate(f'Min: {min_val_loss:.4f}', xy=(min_val_epoch, min_val_loss),\n                xytext=(10, -10), textcoords='offset points', ha='left', va='top',\n                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.5),\n                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n\n    # Add a text box with additional information\n    info_text = f\"Total Epochs: {len(epochs)}\\n\" \\\n                f\"Final Train Loss: {history.history['loss'][-1]:.4f}\\n\" \\\n                f\"Final Val Loss: {history.history['val_loss'][-1]:.4f}\"\n    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n    ax.text(0.05, 0.95, info_text, transform=ax.transAxes, fontsize=10,\n            verticalalignment='top', bbox=props)\n\n    # Improve the layout\n    plt.tight_layout()\n\n    # Save the plot if a save path is provided\n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n\n    # Show the plot\n    plt.show()\n\n# Usage\nplot_enhanced_loss(history, save_path='model_loss_plot.png')","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:01:31.754298Z","iopub.execute_input":"2024-09-07T23:01:31.754775Z","iopub.status.idle":"2024-09-07T23:01:33.677986Z","shell.execute_reply.started":"2024-09-07T23:01:31.754729Z","shell.execute_reply":"2024-09-07T23:01:33.676466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Make Predictions & Visualise Predictions","metadata":{}},{"cell_type":"code","source":"# calculate the metrics\n\ny_pred = model.predict(X_test)\n\nprint()\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f\"Mean Squared Error (MSE): {mse}\")\nprint(f\"Mean Absolute Error (MAE): {mae}\")\nprint(f\"R-squared Score: {r2}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:01:33.679765Z","iopub.execute_input":"2024-09-07T23:01:33.680217Z","iopub.status.idle":"2024-09-07T23:01:34.502345Z","shell.execute_reply.started":"2024-09-07T23:01:33.680171Z","shell.execute_reply":"2024-09-07T23:01:34.500965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Flatten arrays if they are not one-dimensional\ny_test = np.ravel(y_test)\ny_pred = np.ravel(y_pred)\n\n# Calculate metrics\nmse = mean_squared_error(y_test, y_pred)\nmae = mean_absolute_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\n# Create a DataFrame for visualization\ndf = pd.DataFrame({'True Values': y_test, 'Predicted Values': y_pred})\n\n# Plot\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\n# Plot 1: Metrics\naxes[0, 0].text(0.5, 0.8, f'Mean Squared Error (MSE): {mse:.6f}', ha='center', va='center', fontsize=12)\naxes[0, 0].text(0.5, 0.6, f'Mean Absolute Error (MAE): {mae:.6f}', ha='center', va='center', fontsize=12)\naxes[0, 0].text(0.5, 0.4, f'R-squared Score: {r2:.6f}', ha='center', va='center', fontsize=12)\naxes[0, 0].axis('off')\n\n# Plot 2: True vs. Predicted Values (Scatter Plot)\nsns.scatterplot(data=df, x='True Values', y='Predicted Values', ax=axes[0, 1], alpha=0.6)\naxes[0, 1].plot([df['True Values'].min(), df['True Values'].max()],\n                [df['True Values'].min(), df['True Values'].max()], color='red', linestyle='--')\naxes[0, 1].set_title('True vs. Predicted Values')\naxes[0, 1].set_xlabel('True Values')\naxes[0, 1].set_ylabel('Predicted Values')\n\n# Plot 3: Histogram of Errors\nerrors = y_test - y_pred\nsns.histplot(errors, kde=True, ax=axes[1, 0])\naxes[1, 0].set_title('Distribution of Errors')\naxes[1, 0].set_xlabel('Error')\naxes[1, 0].set_ylabel('Frequency')\n\n# Plot 4: Predicted vs. True Values (Line Plot)\nsns.lineplot(x=df.index, y='True Values', data=df, ax=axes[1, 1], label='True Values')\nsns.lineplot(x=df.index, y='Predicted Values', data=df, ax=axes[1, 1], label='Predicted Values', linestyle='--')\naxes[1, 1].set_title('Predicted vs. True Values')\naxes[1, 1].set_xlabel('Index')\naxes[1, 1].set_ylabel('Values')\naxes[1, 1].legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:01:34.504186Z","iopub.execute_input":"2024-09-07T23:01:34.504586Z","iopub.status.idle":"2024-09-07T23:01:35.980192Z","shell.execute_reply.started":"2024-09-07T23:01:34.504546Z","shell.execute_reply":"2024-09-07T23:01:35.978783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mse = mean_squared_error(y_test, y_pred)\nprint(f'Mean Squared Error on Unseen Data: {mse}')","metadata":{"execution":{"iopub.status.busy":"2024-09-07T23:05:01.131216Z","iopub.execute_input":"2024-09-07T23:05:01.131795Z","iopub.status.idle":"2024-09-07T23:05:01.143509Z","shell.execute_reply.started":"2024-09-07T23:05:01.131748Z","shell.execute_reply":"2024-09-07T23:05:01.141932Z"},"trusted":true},"execution_count":null,"outputs":[]}]}